{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projet_IAS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eliascc5/English_proficiency_prediction_NLP/blob/main/preProcessing_NPL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9F8MbJtFfzA"
      },
      "source": [
        "#Libraries used\n",
        "import re            #Regular expression \n",
        "import os            #Operating system\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PxlzyuHKxbY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ada1e4-0f2a-46c6-e937-32c6edaa82b6"
      },
      "source": [
        "#We load our dataset from Drive \n",
        "#Dataset: NICT_JLE_4.1\n",
        "#Reference: https://alaginrc.nict.go.jp/nict_jle/index_E.html\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "#----------------------------------\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn4kVJKfTFpF"
      },
      "source": [
        "def read_text_file(file_path):\n",
        "    with open(file_path, mode='r',encoding=\"utf8\",errors='ignore') as f:\n",
        "      content = f.readlines()\n",
        "      f.close\n",
        "\n",
        "    return content\n",
        "\n",
        "def write_text_file(file_path,fileProccesed,i):\n",
        "    with open(file_path+'/Output'+str(i)+'.txt', 'w') as f_out:\n",
        "      f_out.write('\\n'.join(fileProccesed[i]))\n",
        "      f_out.close\n",
        "\n",
        "def preProcessingData(content):\n",
        "  '''\n",
        "  This function will return a list with the text clean.\n",
        "  Each element corresponds to a line from the files in \"LearnerOriginal\"\n",
        "  '''\n",
        "\n",
        "  file_clean=[]\n",
        "  for j, i in enumerate(content):\n",
        "    if ('<SST_level>' in i):\n",
        "\n",
        "      output_Score=i.strip('</SST_level> \\n')\n",
        "      file_clean.append(output_Score)\n",
        "      #--- Debug ---\n",
        "\n",
        "      print(\"Output Score: \", output_Score) \n",
        "      print(\"---------------------------------\")\n",
        "\n",
        "      \n",
        "    if (\"<B>\" in i):  #that is, all the lines where the candidate spoke \n",
        "    \n",
        "      #We change the name to be readable \n",
        "      lines=i\n",
        "\n",
        "      #In the following list we declare all unwanted characters. \n",
        "      listUndesiredChars=[r'<F>.+?</F>',r'<R>.+?</R>',r'<OL>.+?</OL>',r'<laughter>.+?</laughter>',r'<nvs>.+?</nvs>',r'<CO>.+?</CO>',r'<H.+?</H>']\n",
        "\n",
        "      #TAGS:\n",
        "\n",
        "      #<OL></OL>: Overlapping speech\n",
        "      #<Laughter></Laughter> : Laughter\n",
        "      #<F>:Filler/Filled pause \n",
        "      #<R></R> : Repetition\n",
        "      #<nvs> : Non-verbal Sound\n",
        "      #<JP></JP> : Japanese word \n",
        "      #<H pn=”X”></H> : Learner’s personal information\n",
        "\n",
        "      #-----------------------------------\n",
        "\n",
        "      #<SC></SC> : self-correction\n",
        "      #<SC?></SC?> :Unclear self-Correction \n",
        "      #<.></.> : Short Pause (2 – 3 seconds) \n",
        "      #<..></..> : Long Pause (more than 4 seconds)\n",
        "      #<?></?> : Unclear passage\n",
        "\n",
        "      for tag in listUndesiredChars:\n",
        "        \n",
        "\n",
        "        text_clean = re.split(tag,lines)\n",
        "        text_clean =''.join(text_clean)\n",
        "\n",
        "      \n",
        "      #all the remaining symbols \n",
        "      pattern ='[.?\"-,]' \n",
        "      replacement =''\n",
        "\n",
        "      text_clean = re.split(r'<.+?>',text_clean)\n",
        "      text_clean=''.join(text_clean)\n",
        "\n",
        "      # We remove the characters that are not letters and make everything lowercase \n",
        "      result = re.sub(pattern, replacement, text_clean).lower()  \n",
        "      # We eliminate multiple spaces \n",
        "      result = re.sub('\\s+',' ',result)  \n",
        "   \n",
        "\n",
        "      file_clean.append(result)\n",
        "\n",
        "  return file_clean\n",
        "      \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "  # Path to: READ and WRITE\n",
        "  path_input = '/content/gdrive/MyDrive/NICT_JLE_4.1/LearnerOriginal/'\n",
        "  path_output= r'/content/gdrive/MyDrive/NICT_JLE_4.1/Output/'\n",
        "\n",
        "  # Change the directory\n",
        "  os.chdir(path_input)\n",
        "  #Counter to write all files\n",
        "  i=0\n",
        "  fileProccesed=[]\n",
        "\n",
        "  # iterate through all file\n",
        "  for file in os.listdir():\n",
        "      # Check whether file is in text format or not\n",
        "      if file.endswith(\".txt\"):\n",
        "\n",
        "        file_path = f\"{path_input}/{file}\"\n",
        "        # We read the files to treat \n",
        "        content = read_text_file(file_path)\n",
        "        #The function that clean the files\n",
        "        fileProccesed.append(preProcessingData(content)) \n",
        "        #We write out files\n",
        "        write_text_file(path_output,fileProccesed,i)   \n",
        "        #Counter update\n",
        "        i+=1\n",
        "     "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}